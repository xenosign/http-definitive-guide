# 07. 캐시

- 캐시는 자주 쓰이는 문서의 사본을 자동으로 보관하는 HTTP 장치
- 웹 요청이 캐시에 도착했을 때, 캐시된 로컬 사본이 존재한다면 문서는 해당 캐시로부터 제공

- 캐시가 주는 혜택
  - 캐시는 불필요한 데이터 전송을 줄여서, 네트워크 요금으로 인한 비용을 줄여준다
  - 캐시는 네트워크 병목을 줄여준다. 대역폭을 늘리지 않고도 페이지를 빨리 불러 올 수 있게 된다
  - 캐시는 원 서버에 대한 요청을 줄여준다. 서버는 부하를 줄일 수 있으며 더 빨리 응답할 수 있게 된다
  - 페이지를 먼 곱에서 불러올수록 시간이 많이 걸리는데, 캐시는 거리로 인한 지연을 줄여준다

## 7.1 불필요한 데이터 전송

- 복수의 클라이언트가 자주 쓰이는 원 서버 페이지에 접근 시, 서버는 클라이언트에 응답을 한 번씩 전송하여 서버 입장에서는 동일한 응답을 반복하여 이로 인한 부하가 발생
- 캐시를 이용하면 첫 번째 서버 응답은 캐시에 보관되고, 캐시된 사본이 다른 클라이언트로 부터 들어온 동일한 요청에 사용되어 트래픽 낭비를 줄일 수 있다

## 7.2 대역폭 병목

- 많은 네트워크가 원격 서버보다 로컬 네트워크에 더 넓은 대역폭을 제공하기 때문에, 클라이언트가 서버로 접근하는 외부 네트워크의 경우 가장 느린 네트워크의 속도와 같다
- 따라서 클라이언트가 빠른 로컬 네트워크(LAN)에 있는 캐시로 부터 사본을 가져온다면, 성능을 대폭 개선할 수 있으며 용량이 큰 문서일 경우 큰 폭의 차이를 발생 시킨다

![img.png](images/07_cache_01.png)

## 7.3 갑작스런 요청 쇄도(Flash Crowds)

- 갑작스러운 요청 쇄도가 일어나는 경우 캐싱은 좋은 대비책이 된다

> 책에서 나온 것 처럼 갑자기 특정 뉴스에 대해서 요청이 폭증(Traffic Spike)하는 상황에서의 적절한 캐싱 및 서버 전략은 어떤 것이 좋을까요? <br>
> 1. 해당 뉴스에 대한 문서를 CDN 으로 처리하여 원본 서버에 오기 전에 지역에서 빠르게 처리 (로컬 네트워크에 가까운 개념이겠죠?)
> 2. CDN 에서 처리하지 못한 트래픽은 AWS 의 로드밸런서 혹은 Nginx 등의 리버스 프록시를 사용하여 적절한 트래픽 대응
> 3. 이미 방문한 사용자의 경우 브라우저 캐싱을 통해 처리

## 7.4 거리로 인한 지연

- 아무리 빛의 속도로 통신이 이루어지지만 라우터에 의한 병목과 먼 거리는 지연을 발생 시키고, 이는 가까운 거리에 캐시 서버를 두는 방법으로 해결이 가능하다

## 7.5 적중과 부적중

- 캐시에 요청이 도착했을 때
  - 그에 대응하는 사본이 있는 경우 `캐시 적중(cache hit)`
  - 대응하는 사본이 없는 경우, 요청은 원서버로 전달 `캐시 부적중(cache miss)`

### 7.5.1 재검사(Revalidation)

- 원 서버의 콘텐츠는 변경될 수 있으므로, 캐시는 반드시 그들이 가지고 있는 사본이 여전히 최신인지 점검이 필요
- HTTP 는 해당 과정을 위한 작은 재검사 요청을 정의, 콘텐츠가 변경되지 않았다면 서버는 304(Not Modified) 응답을 제공
- 해당 응답은 원 서버로 부터 콘텐츠 검사 통신이 진행되는 만큼 `캐시 적중` 보다는 느리지만 서버로 부터 문서를 받아올 필요가 없으므로 `캐시 부적중` 보다는 빠르다
- HTTP 는 캐시된 객체를 재확인하기 위해 몇 가지 도구를 제공하는데, 가장 많이 쓰이는 것은 `If-Modified-Since` 헤더가 사용되며 해당 헤더는 캐시된 시간 이후 콘텐츠가 변경된 경우에만 사본을 보내달라는 의미

#### 재검사 적중
- `If-Modified-Since` 헤더 요청을 보냈으나 객체가 변경되지 않은 경우

![img.png](images/07_cache_02.png)

#### 재검사 부적중
- `If-Modified-Since` 헤더 요청을 보냈을 때, 캐시된 사본과 다르다면 서버는 새로운 콘텐츠에 대한 요청을 처리하는 것과 동일하게 200 OK 응답과 콘텐츠를 클라이언트에 보낸다

#### 객체 삭제
- 컨텐츠가 삭제되었다면 일반적은 응답과 마찬가지로 404 Not Found 응답을 돌려준다

### 7.5.2 적중률
- 캐시 적중률은 0 ~ 1 까지의 값으로 되어 있지만, 흔히 `%` 로 표기
- 적중률은 100% 에 가까울 수록 좋지만 40% 정도면 좋은 편
- 문서 적중률은 대기 시간에 영향을 준다

### 7.5.3 바이트 적중률
- 크기가 큰 객체가 캐시 될 때, 트래픽에는 더 큰 기여를 가져다 주므로 어떤 사람들은 `바이트 적중률` 측정값을 선호
- 바이트 적중률은 `캐시를 통해 제공 된 바이트 / 전체 트래픽의 바이트` 를 의미
- 바이트 적중률은 대역폭(= 트래픽 용량) 절약을 최적화 한다

> 문서 적중률 & 바이트 적중률 이해하기 <br>
> - 문서 적중률은 캐셔가 필요한 물품(크기랑 상관 없이)을 가지고 있는 경우. 계산을 하는데 기다릴 필요가 없음
> - 바이트 적중률은 큰 물건을 미리 물류 센터가 아닌 대리점에 입고 시킨 케이스. 물건을 나르는 비용이 절감

### 7.5.4 적중과 부적중의 구별

- 캐시가 적중 되었는지, 부적중 되었는지를 클라이언트는 항상 200 OK 응답을 받기 때문에 구별이 불가능
- 이를 구별하기 위해서는 `Date 헤더` 를 이용, 응답일의 생성일과 현재 시간을 비교하여 해당 응답이 캐시되었는지 구분이 가능

## 7.6 캐시 토폴로지

- 캐시는 한 명의 사용자에게 할당되는 `개인 전용 캐시(private cache)`와 다수의 사용자에게 공유되는 `공용 캐시(public cache)` 로 구분

### 7.6.1 개인 전용 캐시

- 개인 전용 캐시는 큰 저장 공간을 필요로 하지 않으며, 보통 웹 브라우저에서 개인 전용 캐시를 제공

> 크롬 Network 탭을 통해 캐시 확인
![img.png](images/07_cache_03.png)
> - memory cache 가 disk cache 에 비해 더 빠른 것 확인 가능. 그럼에도 disk cache 가 네트워크에 의한 통신 보다는 훨씬 빠른 것도 확인 가능

### 7.6.2 공용 프락시 캐시

- 프락시 캐시라고 불리우며 캐시를 제공하기 위한 특별한 종류의 공유된 프락시 서버로 불필요한 트래픽을 줄이고 성능 개선에 도움을 준다

![img.png](images/07_cache_04.png)

### 7.6.3 프락시 캐시 계층들

- 프락시 캐시는 계층을 가지며 작은 캐시에서 부적중이 발생한 트래픽을 더 큰 부모 캐시가 처리하는 방식으로 구성 된다
- 다만 캐시 계층이 깊어지면 긴 연쇄에 의한 성능 저하로 캐시를 사용하는 목적이 저해될 수 있다

![img.png](images/07_cache_05.png)

### 7.6.4 캐시 망, 콘텐츠 라우팅, 피어링

- 몇몇 네트워크 아키텍쳐는 단순 캐시 계층이 아닌 복잡한 캐시 망(Cache Peering)을 만들고, 프락시 캐시끼리 복잡한 커뮤니케이션을 통해 캐시를 어떤식으로 사용할지 동적으로 결정을 내린다

> 계층형 캐시 구조 대비 캐시 망(Cache Peering)이 가지는 이점
> - 계층형 구조의 경우 동료 캐시(Sibling)가 데이터를 가지고 있어도, 해당 부분을 확인하지 못하고 데이터가 부모 캐시(Parent)에 없으면 원본 서버에 트래픽이 발생. 캐시 망의 경우 주변 캐시를 확인하여 이와 같은 문제를 해결
> - 계층형 구조의 부모 캐시가 죽으면 결국 모든 요청은 원본 서버를 향하지만, 캐시 망의 경우 다른 캐시 서버를 통해 일부 해결이 가능
> - 원본 서버로 나가는 요청은 외부 회선을 사용하는 만큼 비용이 비싸지만, 캐시 망 내부 회선의 경우 비용이 저렴하여 네트워크 비용 절감 가능
> - 특정 콘텐츠에 부하가 걸리는 경우, 캐시 망은 해당 부하를 분산(Load Balancing)하여 문제 해결이 가능

## 7.7 캐시 처리 단계

